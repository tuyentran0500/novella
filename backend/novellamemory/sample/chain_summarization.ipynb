{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.mapreduce import MapReduceChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import ReduceDocumentsChain, MapReduceDocumentsChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.llm import LLMChain\n",
    "from pymongo import MongoClient\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.document_loaders.mongodb import MongodbLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client['novella']\n",
    "storyCollection = db['story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add this import for running in jupyter notebook\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.mongodb import MongodbLoader\n",
    "loader = MongodbLoader(\n",
    "    connection_string=\"mongodb://localhost:27017/\",\n",
    "    db_name=\"novella\",\n",
    "    collection_name=\"chat\",\n",
    "    filter_criteria={},\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_template = \"\"\"The following is a set of chapters\n",
    "        {docs}\n",
    "\n",
    "        Please provide a concise summary of the chapter's core content, focusing on the main events, actions, and significant plot points. \n",
    "        Helpful Answer:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries of my story:\n",
    "{docs}\n",
    "Please analyze the cohesion of the story I've written. Check for repetitiveness between these chapters, \n",
    "ensuring that there is no redundant information or duplicated events, logical flow, and coherence between sentences and paragraphs. \n",
    "Ensure that the plot progresses smoothly and the events are connected logically. Pay attention to the consistency in character descriptions and actions. \n",
    "Look out for any inconsistencies or gaps in the storyline. Additionally, assess the overall readability and engagement factor of the narrative. \n",
    "Provide feedback on how well the story holds together and suggest improvements where necessary. Additionally, please provide an overall score for the story.\n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alone\\miniconda3\\envs\\novella\\Lib\\site-packages\\tiktoken\\core.py:50: RuntimeWarning: coroutine 'MongodbLoader.aload' was never awaited\n",
      "  self._core_bpe = _tiktoken.CoreBPE(mergeable_ranks, special_tokens, pat_str)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Overall, the story you have written seems to have a cohesive plot with a logical flow of events. The chapters progress smoothly, and there are no redundant information or duplicated events. The story maintains a consistent focus on the relationship between Ji-hoon and Nari and their shared love for music.\\n\\nThe character descriptions and actions are consistent throughout the story, and the emotional connection between Ji-hoon and Nari is well-developed. The conflicts they face, such as public scrutiny and societal pressures, add tension and depth to the story.\\n\\nHowever, there are a few areas where the story could be improved. Firstly, it would be beneficial to provide more specific details about Ji-hoon and Nari's musical collaboration in Chapter 3. This would help to further engage the reader and showcase their creative process.\\n\\nAdditionally, it would be helpful to explore the societal pressures and judgment they face in more detail in Chapter 4. This would add depth to their struggles and make their fight against societal expectations more impactful.\\n\\nFurthermore, it would be beneficial to include more specific examples of how Ji-hoon and Nari support each other in pursuing their dreams in Chapter 7. This would highlight their growth as individuals and as a couple.\\n\\nOverall, the story holds together well and maintains reader engagement. With some additional details and further exploration of certain aspects, the story could be even more compelling. I would rate the story a 7.5 out of 10.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_reduce_chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.openai_api_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
